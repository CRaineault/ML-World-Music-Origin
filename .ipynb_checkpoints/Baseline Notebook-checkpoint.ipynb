{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e79c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#very cool notebook to mess around and try things until we get a working baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b33c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports, add more as needed\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sklearn as skl\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b32818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate nominatim geolocator\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ea10e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.161286  7.835325  2.911583 ... -0.364194 -0.364194 -0.364194]\n",
      " [ 0.225763 -0.094169 -0.603646 ...  0.936616  0.936616  0.936616]\n",
      " [-0.692525 -0.517801 -0.788035 ...  0.603755  0.603755  0.603755]\n",
      " ...\n",
      " [-0.77236  -0.670596 -0.84042  ... -0.515309 -0.515309 -0.515309]\n",
      " [-0.996965 -1.099395  3.515274 ...  0.074855  0.074855  0.074855]\n",
      " [-0.150911 -0.094333 -0.568885 ...  5.835585  5.835585  5.835585]]\n"
     ]
    }
   ],
   "source": [
    "#data loading\n",
    "\n",
    "X_data = np.loadtxt(os.path.join('data', 'default_plus_chromatic_features_1059_tracks.txt'), delimiter=',')\n",
    "Y_data = np.loadtxt(os.path.join('data', 'Y_encoding.txt'), delimiter=',')\n",
    "X = data[:, :116]\n",
    "y = Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f76f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'br', 'tz', 'id', 'ke', 'et', 'kh', 'ml', 'th', 'sn', 'cv', 'bz', 'jm', 'mm', 'tw', 'in', 'eg', 'pk', 'ma', 'ir', 'jp', 'dz', 'gr', 'tr', 'cn', 'uz', 'al', 'ge', 'it', 'kg', 'ro', 'gb', 'lt']\n"
     ]
    }
   ],
   "source": [
    "#translating longitude and latitude to country labels\n",
    "''''Y_labels = []\n",
    "\n",
    "y_unique = np.unique(y, axis=0)\n",
    "#print(y_unique)\n",
    "\n",
    "for point in range(0, y_unique.shape[0]):\n",
    "    latitude = y_unique[point,0]\n",
    "    longitude = y_unique[point,1]\n",
    "\n",
    "    location = geolocator.reverse((latitude, longitude))\n",
    "    \n",
    "    \n",
    "    Y_labels.append(location.raw['address']['country_code'])\n",
    "\n",
    "print(Y_labels) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1d2355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#create one-hot encoded y matrix\n",
    "'''num_labels = 33\n",
    "\n",
    "Y_matrix = np.zeros((y.shape[0], num_labels))\n",
    "\n",
    "for point in range(0, y.shape[0]):\n",
    "    loc = np.where(y_unique == y[point, 0])[0]\n",
    "    Y_matrix[point, loc] = 1'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b4f014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing one-hot encoded matrix to new data file for ease of use\n",
    "'''np.savetxt('Y_encoding.txt', Y_matrix, delimiter=',')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b8393f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.68418 ,  0.38837 , -0.082459, ..., -0.423415, -0.423415,\n",
      "        -0.423415],\n",
      "       [ 0.227641,  1.252057,  0.105181, ..., -0.550024, -0.550024,\n",
      "        -0.550024],\n",
      "       [-0.368853, -0.561175, -0.8     , ..., -0.592908, -0.592908,\n",
      "        -0.592908],\n",
      "       ...,\n",
      "       [ 1.740422,  0.917212,  1.422495, ..., -0.30089 , -0.30089 ,\n",
      "        -0.30089 ],\n",
      "       [-0.901138, -0.808483,  1.259502, ..., -0.304974, -0.304974,\n",
      "        -0.304974],\n",
      "       [-0.667114, -0.824345, -0.813485, ..., -0.58474 , -0.58474 ,\n",
      "        -0.58474 ]]), array([[-0.776933, -0.795451, -0.946129, ..., -0.031334, -0.031334,\n",
      "        -0.031334],\n",
      "       [ 0.171762, -0.064024,  0.624968, ...,  0.189211,  0.189211,\n",
      "         0.189211],\n",
      "       [ 0.272374,  0.828918, -0.115317, ...,  3.773076,  3.773076,\n",
      "         3.773076],\n",
      "       ...,\n",
      "       [-0.193796, -0.068105, -0.509288, ...,  0.260685,  0.260685,\n",
      "         0.260685],\n",
      "       [-0.521345, -0.628308, -0.114396, ..., -0.194701, -0.194701,\n",
      "        -0.194701],\n",
      "       [-1.178896, -1.209803, -1.022325, ..., -0.660297, -0.660297,\n",
      "        -0.660297]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "#splitting data into train, cv, test\n",
    "\n",
    "split = skl.model_selection.train_test_split(X, y)\n",
    "\n",
    "train_x = split[0]\n",
    "train_y = split[2]\n",
    "\n",
    "cv_split = skl.model_selection.train_test_split(split[1], split[3])\n",
    "\n",
    "cv_x = cv_split[0]\n",
    "\n",
    "cv_y = cv_split[2]\n",
    "\n",
    "test_x = cv_split[1]\n",
    "\n",
    "text_y = cv_split[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac413bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One v. all logitistic regression for accuracy testing\n",
    "\n",
    "regression_model = Sequential([\n",
    "    Dense(units=33, activation = 'softmax')\n",
    "])\n",
    "\n",
    "regression_model.compile(loss=SparseCategoricalCrossEntropy())\n",
    "\n",
    "regression_model.fit(X, y, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
